<!DOCTYPE html>
<html lang="ja">
    <head>

        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="style.css">
        <title>研究設備</title>

    </head>
    <body>

        <div class="navbar">
            <a href="index.html">ホーム</a>
            <a href="naiyou.html">研究内容</a>
            <a href="dx.html">研究室DX！</a>
            <a href="機械学習.html">機械学習</a>
            <a href="design.html">その他</a>
        </div>

        <div class="content">
            <h2>機械学習</h2>
            <p>自身の研究を行う過程で，ある論文をきっかけに学部生3回生の時，機械学習に興味を持ち，様々な予測について学び，kaggleやsignateといったサイトを利用するなどして，自己学習に励みました．<p>
            <p>ある論文というのも，国立研究開発法人である日本のNIMSが発表した機械学習により発見した磁気冷凍材料の論文が2022年に発行された論文です．もともとMI(materials informatics)に興味があったので，この論文はとても興味深いものでした．</p>
            <p>下記に，機械学習について学んだことの一例を下記に記しました．これはあるお店の売上を予測を考える時に作成したコードです．</p>
            <pre><code class="python-code">import pandas as pd
(中略)...
df = pd.read_csv('data.csv')
X = df[['売上数の週平均',......, '降水量', '時間別通行量']]
y = df['売上']
...
# モデルの設定
xg_reg = xgb.XGBRegressor(
    n_estimators=30,
    max_depth=5,
...
    objective=(他で定義した損失関数)
)
...
# 訓練
xg_reg.fit(X_train, y_train)
# 予測
preds = xg_reg.predict(X_test)
...
rmse = np.sqrt(mean_squared_error(y_test, preds))
...
            </code></pre>
            <p>・データ収集,データクリーニング</p>
            <p>・ハイパーパラメータ調整</p>
            <p>・様々な損失関数の適用</p>
            <p>上記3点等を行いました．機械学習をしていて感じたことは，データ収集が一番大変でした．特に日本においては，国民性によるものか，データが収集のしにくさが目立ちました．企業においても，情報を公開するということは競合他社等に利用されるリスクが顕在するので，なかなかオープンデータは集まりにくいのかなとも感じました．また，損失関数だけでもたくさんあり，どれがこのモデルに適正な関数か．このこと考えるのには経験が必要だと痛感しました．ただ，適切な関数や，パラメータを見つけて，精度を上げられた時は嬉しいです．</p>
            <p>今後はさらに大きいデータサイズのものを扱い，機械学習をしていきたいと考えています．</p>
            <p>しかしながら，周りに大きいデータセットはなかなか存在しないので，大きいデータセット触れられ，様々な専門の機械学習の事例に関して学べるkaggleなどのサイトを利用していきたいです．</p>
        </div>

    </body>

</html>